---
title: "Roadmap"
format: 
  html:
    page-layout: full
---

```{python}
#| label: roadmap
#| echo: false
#| output: asis

import vote
    
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from itables import init_notebook_mode, show

init_notebook_mode(all_interactive=False)

# Load voting results
results = vote.run_election('./roadmap/votes', 1, './roadmap/tasks.csv')
avg_table = results['avg_table']

# Load all tasks (preserve Effort and other columns)
tasks_df = pd.read_csv('./roadmap/tasks.csv')
if 'Priority' not in tasks_df.columns:
    tasks_df['Priority'] = 0
# Merge in Priority from avg_table (by Task, left join)
priority_df = avg_table[['Task', 'Priority']]
df = tasks_df.merge(priority_df, on='Task', how='left', suffixes=('', '_voted'))
# Use voted Priority if available, else fallback to original
df['Priority'] = df['Priority_voted'].fillna(df['Priority'])
df.drop(columns=['Priority_voted'], inplace=True)

# Ensure Effort is numeric, fill missing with 0, and filter out negative Effort
df['Effort'] = pd.to_numeric(df['Effort'], errors='coerce').fillna(0)
df = df[df['Effort'] >= 0]

# Filter out completed and archived tasks (do not show in chart)
if 'Completed_on' in df.columns:
    df = df[df['Completed_on'].isna()]
if 'Archived_on' in df.columns:
    df = df[df['Archived_on'].isna() | (df['Archived_on'] == '')]
df = df.drop(columns=['Completed_on', 'Archived_on'], errors='ignore')

# Reorder columns
if 'Created_on' in df.columns:
    df = df[['Category', 'Task', 'Priority', 'Effort', 'Notes', 'Created_on']]
else:
    df = df[['Category', 'Task', 'Priority', 'Effort', 'Notes']]

# Use Latency (age in days since Created_on) as x-axis, Effort as marker size
import numpy as np
from datetime import datetime
min_size = 60  # Increased from 30 to 60
max_size = 150  # Increased from 100 to 150
def compute_latency(row):
    try:
        if 'Created_on' not in row or pd.isna(row['Created_on']):
            return np.nan
        created = pd.to_datetime(row['Created_on'], errors='coerce')
        if pd.isna(created):
            return np.nan
        return (datetime.now() - created).days
    except Exception:
        return np.nan
df['Latency'] = df.apply(compute_latency, axis=1)

# Calculate raw vote count for each task
votes_dict = vote.get_votes('./roadmap/votes')
vote_counts = {}
for voter, ballot in votes_dict.items():
    for task, vote_val in ballot.items():
        vote_counts[task] = vote_counts.get(task, 0) + vote_val

total_votes = sum(vote_counts.values()) if vote_counts else 1
# Add normalized vote count to dataframe
# If a task has no votes, set to 0
df['RawVoteCount'] = df['Task'].map(lambda t: vote_counts.get(t, 0))
df['NormVoteCount'] = df['RawVoteCount'] / total_votes



# Compute Pareto frontier for Effort vs Priority (minimize Effort for each Priority)
def pareto_frontier_min_effort(df):
    # For each unique Priority (descending), keep the task with the lowest Effort so far
    sorted_df = df.sort_values(['Priority', 'Effort'], ascending=[False, True]).reset_index(drop=True)
    pareto = []
    min_effort = None
    for _, row in sorted_df.iterrows():
        effort = row['Effort']
        if min_effort is None or effort < min_effort:
            pareto.append(row['Task'])
            min_effort = effort
    return pareto

pareto_ep = pareto_frontier_min_effort(df)
df['Pareto_EP'] = df['Task'].isin(pareto_ep)
# Compute Pareto frontier for Priority vs Effort (maximize Priority for each Effort)
def pareto_frontier_max_priority(df):
    # For each unique Effort (ascending), keep the task with the highest Priority so far
    sorted_df = df.sort_values(['Effort', 'Priority'], ascending=[True, False]).reset_index(drop=True)
    pareto = []
    max_priority = None
    for _, row in sorted_df.iterrows():
        priority = row['Priority']
        if max_priority is None or priority > max_priority:
            pareto.append(row['Task'])
            max_priority = priority
    return pareto

pareto_ep = pareto_frontier_min_effort(df)

# Chart 1: Effort (x) vs Priority (y) with Pareto
effort_sizes = df['Effort'].fillna(min_size)
fig_ep = px.scatter(
    df,
    x='Effort',
    y='Priority',
    color='Pareto_EP',
    size=effort_sizes,
    hover_data=['Category', 'Notes', 'Effort', 'Priority', 'Latency', 'Created_on'],
    title='Feature Roadmap: Effort vs Priority (Pareto Highlighted, Effort Size)',
    labels={'Effort': 'Effort (1-100 Scale)', 'Priority': 'Priority', 'Pareto_EP': 'Pareto Optimal', 'Created_on': 'Created', 'Latency': 'Age (days)'}
)
pareto_points_ep = df[df['Pareto_EP']].sort_values('Effort')
if len(pareto_points_ep) > 1:
    pareto_line_ep = go.Scatter(
        x=pareto_points_ep['Effort'],
        y=pareto_points_ep['Priority'],
        mode='lines+markers',
        name='Pareto Frontier',
        line=dict(color='orange', width=3, dash='solid'),
        marker=dict(size=10, color='orange', symbol='diamond')
    )
    fig_ep.add_trace(pareto_line_ep)
pareto_df_ep = df[df['Pareto_EP']]
if len(pareto_df_ep) >= 3:
    try:
        from scipy.spatial import ConvexHull
        import numpy as np
        points = pareto_df_ep[['Effort', 'Priority']].values
        hull = ConvexHull(points)
        hull_points = points[hull.vertices]
        hull_trace_ep = go.Scatter(
            x=hull_points[:,0],
            y=hull_points[:,1],
            mode='lines+markers',
            name='Pareto Convex Hull (scipy)',
            line=dict(color='orange', width=3, dash='dash'),
            marker=dict(size=8, color='orange', symbol='diamond')
        )
fig_pl = px.scatter(
    df,
    x='Priority',
    y='Latency',
    color='Pareto_EP',
    size=effort_sizes,
    hover_data=['Category', 'Notes', 'Effort', 'Priority', 'Latency', 'Created_on'],
    title='Feature Roadmap: Priority vs Latency (Pareto Highlighted, Effort Size)',
    labels={'Effort': 'Effort (1-100 Scale)', 'Priority': 'Priority', 'Pareto_EP': 'Pareto Optimal', 'Latency': 'Age (days)', 'Created_on': 'Created'}
)
# Draw Pareto front line for Priority vs Latency
pareto_points_pl = df[df['Pareto_EP']].sort_values('Priority')
if len(pareto_points_pl) > 1:
    pareto_line_pl = go.Scatter(
        x=pareto_points_pl['Priority'],
        y=pareto_points_pl['Latency'],
        mode='lines+markers',
        name='Pareto Frontier',
        line=dict(color='orange', width=3, dash='solid'),
        marker=dict(size=10, color='orange', symbol='diamond')
    )
    fig_pl.add_trace(pareto_line_pl)
fig_pl.show()
    try:
        fig_ep.add_trace(hull_trace_ep)
    except ImportError:
        pass
fig_el = px.scatter(
    df,
    x='Effort',
    y='Latency',
    color='Pareto_EP',
    size=effort_sizes,
    hover_data=['Category', 'Notes', 'Effort', 'Priority', 'Latency', 'Created_on'],
    title='Feature Roadmap: Effort vs Latency (Pareto Highlighted, Effort Size)',
    labels={'Effort': 'Effort (1-100 Scale)', 'Latency': 'Age (days)', 'Pareto_EP': 'Pareto Optimal', 'Priority': 'Priority', 'Created_on': 'Created'}
)
# Draw Pareto front line for Effort vs Latency
pareto_points_el = df[df['Pareto_EP']].sort_values('Effort')
if len(pareto_points_el) > 1:
    pareto_line_el = go.Scatter(
        x=pareto_points_el['Effort'],
        y=pareto_points_el['Latency'],
        mode='lines+markers',
        name='Pareto Frontier',
        line=dict(color='orange', width=3, dash='solid'),
        marker=dict(size=10, color='orange', symbol='diamond')
    )
    fig_el.add_trace(pareto_line_el)
fig_el.show()
fig_ep.show()

# Chart 2: Priority (x) vs Latency (y)
fig_pl = px.scatter(
    df,
    x='Priority',
    y='Latency',
    color='Pareto_EP',
    size=effort_sizes,
    hover_data=['Category', 'Notes', 'Effort', 'Priority', 'Latency', 'Created_on'],
    title='Feature Roadmap: Priority vs Latency (Pareto Highlighted, Effort Size)',
    labels={'Effort': 'Effort (1-100 Scale)', 'Priority': 'Priority', 'Pareto_EP': 'Pareto Optimal', 'Latency': 'Age (days)', 'Created_on': 'Created'}
)
fig_pl.show()

# Chart 3: Effort (x) vs Latency (y)
fig_el = px.scatter(
    df,
    x='Effort',
    y='Latency',
    color='Pareto_EP',
    size=effort_sizes,
    hover_data=['Category', 'Notes', 'Effort', 'Priority', 'Latency', 'Created_on'],
    title='Feature Roadmap: Effort vs Latency (Pareto Highlighted, Effort Size)',
    labels={'Effort': 'Effort (1-100 Scale)', 'Latency': 'Age (days)', 'Pareto_EP': 'Pareto Optimal', 'Priority': 'Priority', 'Created_on': 'Created'}
)

fig_el.show()

print("""

## How to Interpret the Roadmap Charts

**Chart 1: Effort vs Priority (Pareto Highlighted)**
- **X-axis (Effort):** Estimated work required (lower is better).
- **Y-axis (Priority):** Importance or value to the project (higher is better).
- **Pareto Frontier:** Orange line and diamonds show the most valuable tasks for the least effort. Focus on these for maximum impact.
- **Interpretation:** Tasks near the top-left are "quick wins" (high value, low effort). Tasks on the Pareto line are optimal trade-offs.

**Chart 2: Priority vs Latency**
- **X-axis (Priority):** Importance or value to the project.
- **Y-axis (Latency):** Age of the task in days (higher means older).
- **Interpretation:** Top-right tasks are high-priority and have been waiting the longest—consider addressing these soon.

**Chart 3: Effort vs Latency**
- **X-axis (Effort):** Estimated work required.
- **Y-axis (Latency):** Age of the task in days.
- **Interpretation:** Top-left tasks are easy to do and have been waiting a long time—these are good candidates for quick progress.

Use these charts to balance quick wins, urgent priorities, and neglected tasks for effective game project planning.
## Archived Tasks

Archived tasks

<details>
<summary>Show archived tasks</summary>
""")

archived_tasks_df = vote.get_archived_tasks_table('./roadmap/tasks.csv')
archived_tasks_df['Notes'] = archived_tasks_df['Notes'].fillna("")
archived_tasks_df.reset_index(drop=True, inplace=True)

show(archived_tasks_df)

print("""
</details>
""")

print("""

## Raw Votes

<details>
<summary>Show raw votes table</summary>

Raw votes count

""")

votes_dict = vote.get_votes('./roadmap/votes')
votes_df = pd.DataFrame(votes_dict)
votes_df = votes_df.fillna(0)
show(votes_df, paging=False)

print("""
</details>
""")
```
